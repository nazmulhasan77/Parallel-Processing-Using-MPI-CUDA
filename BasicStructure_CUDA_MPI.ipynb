{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97a8a178",
   "metadata": {},
   "source": [
    "## MPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88734261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing basic_mpi.c\n"
     ]
    }
   ],
   "source": [
    "%%writefile basic_mpi.c\n",
    "#include <mpi.h>    // MPI header\n",
    "#include <stdio.h>  // For printf\n",
    "#include <stdlib.h> // For exit()\n",
    "\n",
    "int main(int argc, char** argv) {\n",
    "\n",
    "    // ===============================\n",
    "    // 1. Initialize MPI environment\n",
    "    // ===============================\n",
    "    // Arguments: pointers to argc and argv\n",
    "    // Returns: MPI_SUCCESS if successful\n",
    "    MPI_Init(&argc, &argv);\n",
    "\n",
    "    // ===============================\n",
    "    // 2. Determine total number of processes\n",
    "    // ===============================\n",
    "    int world_size;\n",
    "    MPI_Comm_size(MPI_COMM_WORLD, &world_size);\n",
    "    // MPI_COMM_WORLD is the default communicator including all processes\n",
    "\n",
    "    // ===============================\n",
    "    // 3. Determine the rank of this process\n",
    "    // ===============================\n",
    "    int world_rank;\n",
    "    MPI_Comm_rank(MPI_COMM_WORLD, &world_rank);\n",
    "    // Rank is an integer from 0 to world_size-1, unique to each process\n",
    "\n",
    "    // ===============================\n",
    "    // 4. (Optional) Get processor name\n",
    "    // ===============================\n",
    "    char processor_name[MPI_MAX_PROCESSOR_NAME];\n",
    "    int name_len;\n",
    "    MPI_Get_processor_name(processor_name, &name_len);\n",
    "\n",
    "    // ===============================\n",
    "    // 5. Example: Point-to-Point Communication\n",
    "    // ===============================\n",
    "    // Send data from rank 0 to rank 1\n",
    "    if (world_rank == 0) {\n",
    "        int number = 42;\n",
    "        MPI_Send(&number,     // data to send\n",
    "                 1,           // number of elements\n",
    "                 MPI_INT,     // data type\n",
    "                 1,           // destination rank\n",
    "                 0,           // message tag\n",
    "                 MPI_COMM_WORLD); // communicator\n",
    "        printf(\"Process 0 sent number %d to process 1\\n\", number);\n",
    "    } else if (world_rank == 1) {\n",
    "        int number;\n",
    "        MPI_Recv(&number,     // buffer to receive\n",
    "                 1,           // number of elements\n",
    "                 MPI_INT,     // data type\n",
    "                 0,           // source rank\n",
    "                 0,           // message tag\n",
    "                 MPI_COMM_WORLD, // communicator\n",
    "                 MPI_STATUS_IGNORE); // status (can store info about message)\n",
    "        printf(\"Process 1 received number %d from process 0\\n\", number);\n",
    "    }\n",
    "\n",
    "    // ===============================\n",
    "    // 6. Example: Collective Communication\n",
    "    // ===============================\n",
    "    // Broadcast a number from rank 0 to all processes\n",
    "    int broadcast_number;\n",
    "    if (world_rank == 0) {\n",
    "        broadcast_number = 100;\n",
    "    }\n",
    "    MPI_Bcast(&broadcast_number, 1, MPI_INT, 0, MPI_COMM_WORLD);\n",
    "    printf(\"Process %d received broadcast number %d\\n\", world_rank, broadcast_number);\n",
    "\n",
    "    // ===============================\n",
    "    // 7. Example: Reduction Operation\n",
    "    // ===============================\n",
    "    // Sum all ranks into rank 0\n",
    "    int sum_of_ranks;\n",
    "    MPI_Reduce(&world_rank,       // send buffer\n",
    "               &sum_of_ranks,     // receive buffer\n",
    "               1,                 // number of elements\n",
    "               MPI_INT,           // data type\n",
    "               MPI_SUM,           // operation\n",
    "               0,                 // root process\n",
    "               MPI_COMM_WORLD);   // communicator\n",
    "    if (world_rank == 0) {\n",
    "        printf(\"Sum of ranks = %d\\n\", sum_of_ranks);\n",
    "    }\n",
    "\n",
    "    // ===============================\n",
    "    // 8. Finalize MPI environment\n",
    "    // ===============================\n",
    "    MPI_Finalize();\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28e89cd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process 0 sent number 42 to process 1\n",
      "Process 0 received broadcast number 100\n",
      "Process 1 received number 42 from process 0\n",
      "Process 1 received broadcast number 100\n",
      "Process 2 received broadcast number 100\n",
      "Process 3 received broadcast number 100\n",
      "Sum of ranks = 6\n"
     ]
    }
   ],
   "source": [
    "!mpicc -o basic_mpi basic_mpi.c\n",
    "!mpirun -np 4 ./basic_mpi\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a5ae97",
   "metadata": {},
   "source": [
    "## CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d9e3d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing cuda_example.cu\n"
     ]
    }
   ],
   "source": [
    "%%writefile cuda_example.cu\n",
    "#include <cuda_runtime.h>  // CUDA runtime API\n",
    "#include <stdio.h>          // Standard IO\n",
    "#include <stdlib.h>         // For malloc/free\n",
    "\n",
    "// ===============================\n",
    "// 1. Define a CUDA kernel\n",
    "// ===============================\n",
    "__global__ void addKernel(int *d_c, const int *d_a, const int *d_b, int n) {\n",
    "    // Compute global thread index\n",
    "    int i = threadIdx.x + blockIdx.x * blockDim.x;\n",
    "    \n",
    "    if (i < n) {\n",
    "        d_c[i] = d_a[i] + d_b[i]; // Each thread adds one element\n",
    "    }\n",
    "}\n",
    "\n",
    "// ===============================\n",
    "// 2. Host code (CPU)\n",
    "// ===============================\n",
    "int main() {\n",
    "    int n = 16; // Size of arrays\n",
    "    size_t size = n * sizeof(int);\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2a. Allocate host memory\n",
    "    // -------------------------------\n",
    "    int *h_a = (int*)malloc(size);\n",
    "    int *h_b = (int*)malloc(size);\n",
    "    int *h_c = (int*)malloc(size);\n",
    "\n",
    "    // Initialize host arrays\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        h_a[i] = i;\n",
    "        h_b[i] = i * 2;\n",
    "    }\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2b. Allocate device memory\n",
    "    // -------------------------------\n",
    "    int *d_a, *d_b, *d_c;\n",
    "    cudaMalloc((void**)&d_a, size);  // Allocate array on GPU\n",
    "    cudaMalloc((void**)&d_b, size);\n",
    "    cudaMalloc((void**)&d_c, size);\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2c. Copy data from host to device\n",
    "    // -------------------------------\n",
    "    cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice);\n",
    "    cudaMemcpy(d_b, h_b, size, cudaMemcpyHostToDevice);\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2d. Launch kernel\n",
    "    // -------------------------------\n",
    "    int threadsPerBlock = 8;\n",
    "    int blocksPerGrid = (n + threadsPerBlock - 1) / threadsPerBlock; // Ceiling division\n",
    "    addKernel<<<blocksPerGrid, threadsPerBlock>>>(d_c, d_a, d_b, n);\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2e. Copy result back to host\n",
    "    // -------------------------------\n",
    "    cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost);\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2f. Print results\n",
    "    // -------------------------------\n",
    "    for (int i = 0; i < n; i++) {\n",
    "        printf(\"%d + %d = %d\\n\", h_a[i], h_b[i], h_c[i]);\n",
    "    }\n",
    "\n",
    "    // -------------------------------\n",
    "    // 2g. Free device and host memory\n",
    "    // -------------------------------\n",
    "    cudaFree(d_a);\n",
    "    cudaFree(d_b);\n",
    "    cudaFree(d_c);\n",
    "    free(h_a);\n",
    "    free(h_b);\n",
    "    free(h_c);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41f9c59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 + 0 = 0\n",
      "1 + 2 = 3\n",
      "2 + 4 = 6\n",
      "3 + 6 = 9\n",
      "4 + 8 = 12\n",
      "5 + 10 = 15\n",
      "6 + 12 = 18\n",
      "7 + 14 = 21\n",
      "8 + 16 = 24\n",
      "9 + 18 = 27\n",
      "10 + 20 = 30\n",
      "11 + 22 = 33\n",
      "12 + 24 = 36\n",
      "13 + 26 = 39\n",
      "14 + 28 = 42\n",
      "15 + 30 = 45\n"
     ]
    }
   ],
   "source": [
    "!nvcc -o cuda_example cuda_example.cu   # Compile\n",
    "!./cuda_example                         # Run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e2dc0c",
   "metadata": {},
   "source": [
    "| Step                         | Function / Concept                                   | Arguments                            | Purpose                                                                         |\n",
    "| ---------------------------- | ---------------------------------------------------- | ------------------------------------ | ------------------------------------------------------------------------------- |\n",
    "| **Kernel declaration**       | `__global__ void kernel(...)`                        | `__global__`                         | Declares a function that runs on GPU, called from host                          |\n",
    "| **Thread index**             | `threadIdx`, `blockIdx`, `blockDim`                  | `threadIdx.x`, `blockIdx.x`          | Compute unique global thread index: `i = threadIdx.x + blockIdx.x * blockDim.x` |\n",
    "| **Host memory allocation**   | `malloc(size)`                                       | size in bytes                        | Allocate memory on CPU                                                          |\n",
    "| **Device memory allocation** | `cudaMalloc((void**)&d_a, size)`                     | pointer to GPU memory, size          | Allocate memory on GPU                                                          |\n",
    "| **Memory copy H→D**          | `cudaMemcpy(d_a, h_a, size, cudaMemcpyHostToDevice)` | destination, source, size, direction | Copy data from CPU to GPU                                                       |\n",
    "| **Kernel launch**            | `kernel<<<blocks, threads>>>(args)`                  | blocksPerGrid, threadsPerBlock       | Execute kernel on GPU with parallel threads                                     |\n",
    "| **Memory copy D→H**          | `cudaMemcpy(h_c, d_c, size, cudaMemcpyDeviceToHost)` | destination, source, size, direction | Copy results from GPU to CPU                                                    |\n",
    "| **Free GPU memory**          | `cudaFree(d_a)`                                      | pointer                              | Release GPU memory                                                              |\n",
    "| **Free host memory**         | `free(h_a)`                                          | pointer                              | Release CPU memory                                                              |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
